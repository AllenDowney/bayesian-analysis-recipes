{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixtures\n",
    "\n",
    "Sometimes, our data look like they are generated by a \"mixture\" model. What do we mean by that? In statistics land, it means we believe that there are \"mixtures\" of subpopulations generating the data that we observe. A common activity, then, is to estimate the subpopulation parameters.\n",
    "\n",
    "Let's take a look at it by generating some simulated data to illustrate the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by first generating a mixture distribution that is composed of unit width Gaussians (i.e. $ N(\\mu, 1) $) that are slightly overlapping.\n",
    "\n",
    "$$ pop \\sim GaussianMixture(\\mu=[0, 3], \\sigma=[1, 1]) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixture_data(mus, sizes):\n",
    "    \"\"\"\n",
    "    Generates mixture data\n",
    "    \"\"\"\n",
    "    subpop1 = np.random.normal(loc=mus[0], scale=1, size=sizes[0])\n",
    "    subpop2 = np.random.normal(loc=mus[1], scale=1, size=sizes[1])\n",
    "    mixture = np.concatenate([subpop1, subpop2])\n",
    "    return mixture\n",
    "\n",
    "mixture = generate_mixture_data(mus=[0, 3], sizes=[20000, 20000])\n",
    "plt.hist(mixture, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to reiterate the point, one of the Gaussian distributions has a mean at 0, and the other has a mean at 3. Both subpopulations are present in equal proportions in the larger population, i.e. they have equal weighting.\n",
    "\n",
    "Let's see if we can use PyMC3 to recover those parameters. Since we know that there are two mixture components, we can encode this in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    mu = pm.Cauchy('mu', alpha=1, beta=1, shape=(2,))\n",
    "    sd = pm.HalfCauchy('sd', beta=1, shape=(2,))\n",
    "    \n",
    "    w = pm.Dirichlet('w', a=np.array([1, 1]))  # mixture component weights. See below!\n",
    "    \n",
    "    like = pm.NormalMixture('like', w=w, mu=mu, sd=sd, observed=mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, sometimes, in our final population, one sub-population is present at a lower frequency than the other sub-population. Let's try to simulate that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = generate_mixture_data(mus=[0, 3], sizes=[20000, 2000])  # One is at 1/10 the size of the other.\n",
    "plt.hist(mixture, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    mu = pm.Cauchy('mu', alpha=1, beta=1, shape=(2,))\n",
    "    sd = pm.HalfCauchy('sd', beta=1, shape=(2,))\n",
    "    \n",
    "    w = pm.Dirichlet('w', a=np.array([1, 1]))  # mixture component weights. See below!\n",
    "    \n",
    "    like = pm.NormalMixture('like', w=w, mu=mu, sd=sd, observed=mixture)\n",
    "\n",
    "with model:\n",
    "    trace = pm.sample(2000)\n",
    "    pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really good. We have fewer samples for the group with $ \\mu = 3 $, which thus means that we are much less confident about the value of $ \\mu $ and $ \\sigma $. What's neat is that we are nonetheless equally confident of the relative weighting of the two groups: one is much smaller in proportion than the other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Mixtures\n",
    "\n",
    "We used Gaussian (a.k.a. Normal) distributions for generating the data. However, what if the data didn't come from a Gaussian distribution, but instead came from two Poissons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poisson_mixtures(lams, sizes):\n",
    "    grp1 = np.random.poisson(lam=lams[0], size=sizes[0])\n",
    "    grp2 = np.random.poisson(lam=lams[1], size=sizes[1])\n",
    "    \n",
    "    mixture = np.concatenate([grp1, grp2])\n",
    "    return mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = generate_poisson_mixtures(lams=[14, 30], sizes=[200, 150])\n",
    "plt.hist(mixture)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    lam = pm.Exponential('lam', lam=1, shape=(2,))\n",
    "    components = pm.Poisson('components', mu=lam, shape=(2,))\n",
    "    \n",
    "    w = pm.Dirichlet('w', a=np.array([1, 1]))  # mixture component weights. See below!\n",
    "    \n",
    "    like = pm.Mixture('like', w=w, comp_dists=components, observed=mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
