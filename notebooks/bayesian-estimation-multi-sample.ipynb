{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Type\n",
    "\n",
    "The Bayesian estimation model is widely applicable across a number of scenarios. The classical scenario is when we have an experimental design where there is a control vs. a treatment, and we want to know what the difference is between the two. Here, \"estimation\" is used to estimate the \"true\" value for the control and the \"true\" value for the treatment, and the \"Bayesian\" part refers to the computation of the uncertainty surrounding the parameter. \n",
    "\n",
    "Bayesian estimation's advantages over the classical t-test was first described by John Kruschke (2013). \n",
    "\n",
    "In this notebook, I provide a concise implementation suitable for two-sample and multi-sample inference.\n",
    "\n",
    "## Data structure\n",
    "\n",
    "To use it with this model, the data should be structured as such:\n",
    "\n",
    "- Each row is one measurement.\n",
    "- The columns should indicate, at the minimum:\n",
    "    - What treatment group the sample belonged to.\n",
    "    - The measured value.\n",
    "\n",
    "## Extensions to the model\n",
    "\n",
    "As of now, the model only samples posterior distributions of measured values. The model, then, may be extended to compute differences in means (sample vs. control) or effect sizes, complete with uncertainty around it. Use `pm.Deterministic(...)` to ensure that those statistics' posterior distributions, i.e. uncertainty, are also computed.\n",
    "\n",
    "## Reporting summarized findings\n",
    "\n",
    "Here are examples of how to summarize the findings.\n",
    "\n",
    "> Treatment group A was greater than control by x units (95% HPD: [`lower`, `upper`]). \n",
    "\n",
    "> Treatment group A was higher than control (effect size 95% HPD: [`lower`, `upper`]). \n",
    "\n",
    "## Other notes\n",
    "\n",
    "Here, we make a few modelling choices.\n",
    "\n",
    "1. We care only about the `normalized_measurement` column, and so we choose the t-distribution to model it, as we don't have a good \"mechanistic\" model that incorporates measurement error of OD600 and 'measurement'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/biofilm.csv')\n",
    "continuous_cols = ['OD600', 'ST', 'replicate', 'measurement', 'normalized_measurement']\n",
    "for c in continuous_cols:\n",
    "    df[c] = pm.floatX(df[c])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['isolate'])\n",
    "df['indices'] = le.transform(df['isolate']).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as best:\n",
    "    nu = pm.Exponential('nu_minus_one', lam=1/30) + 1\n",
    "    \n",
    "    fold = pm.Flat('fold', shape=len(le.classes_))\n",
    "    \n",
    "    var = pm.HalfCauchy('var', beta=1, shape=len(le.classes_))\n",
    "    \n",
    "    mu = fold[df['indices'].values]\n",
    "    sd = var[df['indices'].values]\n",
    "    \n",
    "    like = pm.StudentT('like', mu=mu, sd=sd, nu=nu, \n",
    "                       observed=df['normalized_measurement'])\n",
    "    \n",
    "    # Compute differences\n",
    "    diffs = pm.Deterministic('differences', fold - fold[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with best:\n",
    "    trace = pm.sample(draws=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['fold'], ylabels=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['differences'], ylabels=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
